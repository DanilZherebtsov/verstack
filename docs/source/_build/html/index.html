
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17: http://docutils.sourceforge.net/" />

  
  <!-- Licensed under the Apache 2.0 License -->
  <link rel="stylesheet" type="text/css" href="_static/fonts/open-sans/stylesheet.css" />
  <!-- Licensed under the SIL Open Font License -->
  <link rel="stylesheet" type="text/css" href="_static/fonts/source-serif-pro/source-serif-pro.css" />
  <link rel="stylesheet" type="text/css" href="_static/css/bootstrap.min.css" />
  <link rel="stylesheet" type="text/css" href="_static/css/bootstrap-theme.min.css" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
    <title>verstack 2.0.1 Documentation &#8212; verstack 0.1.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/guzzle.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  
   

  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="nav-item nav-item-0"><a href="#">verstack 0.1.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">verstack 2.0.1 Documentation</a></li> 
      </ul>
    </div>
    <div class="container-wrapper">

      <div id="mobile-toggle">
        <a href="#"><span class="glyphicon glyphicon-align-justify" aria-hidden="true"></span></a>
      </div>
  <div id="left-column">
    <div class="sphinxsidebar"><a href="
    #" class="text-logo">verstack</a>
<div class="sidebar-block">
  <div class="sidebar-wrapper">
    <h2>Contents</h2>
    <div class="sidebar-localtoc">
      <ul>
<li><a class="reference internal" href="#">verstack 2.0.1 Documentation</a><ul>
<li><a class="reference internal" href="#dateparser">DateParser</a><ul>
<li><a class="reference internal" href="#parameters">Parameters</a></li>
<li><a class="reference internal" href="#methods">Methods</a></li>
<li><a class="reference internal" href="#examples">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#lgbmtuner">LGBMTuner</a><ul>
<li><a class="reference internal" href="#logic">Logic</a></li>
<li><a class="reference internal" href="#id1">Parameters</a></li>
<li><a class="reference internal" href="#id2">Methods</a></li>
<li><a class="reference internal" href="#id3">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#nanimputer">NaNImputer</a><ul>
<li><a class="reference internal" href="#id4">Logic</a></li>
<li><a class="reference internal" href="#id5">Parameters</a></li>
<li><a class="reference internal" href="#id6">Methods</a></li>
<li><a class="reference internal" href="#id7">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#multicore">Multicore</a><ul>
<li><a class="reference internal" href="#id8">Logic</a></li>
<li><a class="reference internal" href="#id9">Parameters</a></li>
<li><a class="reference internal" href="#id10">Methods</a></li>
<li><a class="reference internal" href="#id11">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#threshtuner">ThreshTuner</a><ul>
<li><a class="reference internal" href="#id12">Logic</a></li>
<li><a class="reference internal" href="#id13">Parameters</a></li>
<li><a class="reference internal" href="#id14">Methods</a></li>
<li><a class="reference internal" href="#id15">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#stratified-continuous-split">stratified_continuous_split</a><ul>
<li><a class="reference internal" href="#id16">Parameters</a></li>
<li><a class="reference internal" href="#id17">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#categoric-encoders">categoric_encoders</a><ul>
<li><a class="reference internal" href="#factorizer">Factorizer</a><ul>
<li><a class="reference internal" href="#id18">Logic</a></li>
<li><a class="reference internal" href="#id19">Parameters</a></li>
<li><a class="reference internal" href="#id20">Methods</a></li>
<li><a class="reference internal" href="#id21">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#onehotencoder">OneHotEncoder</a><ul>
<li><a class="reference internal" href="#id22">Logic</a></li>
<li><a class="reference internal" href="#id23">Parameters</a></li>
<li><a class="reference internal" href="#id24">Methods</a></li>
<li><a class="reference internal" href="#id25">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#frequencyencoder">FrequencyEncoder</a><ul>
<li><a class="reference internal" href="#id26">Logic</a></li>
<li><a class="reference internal" href="#id27">Parameters</a></li>
<li><a class="reference internal" href="#id28">Methods</a></li>
<li><a class="reference internal" href="#id29">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#meantargetencoder">MeanTargetEncoder</a><ul>
<li><a class="reference internal" href="#id30">Logic</a></li>
<li><a class="reference internal" href="#id31">Parameters</a></li>
<li><a class="reference internal" href="#id32">Methods</a></li>
<li><a class="reference internal" href="#id33">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#weightofevidenceencoder">WeightOfEvidenceEncoder</a><ul>
<li><a class="reference internal" href="#id34">Logic</a></li>
<li><a class="reference internal" href="#id36">Parameters</a></li>
<li><a class="reference internal" href="#id38">Methods</a></li>
<li><a class="reference internal" href="#id39">Examples</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#timer">timer</a><ul>
<li><a class="reference internal" href="#id40">Examples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#links">Links</a></li>
</ul>
</li>
</ul>

    </div>
  </div>
</div>
      
    </div>
  </div>
        <div id="right-column">
          
          <div role="navigation" aria-label="breadcrumbs navigation">
            <ol class="breadcrumb">
              <li><a href="#">Docs</a></li>
              
              <li>verstack 2.0.1 Documentation</li>
            </ol>
          </div>
          
          <div class="document clearer body">
            
  <section id="verstack-2-0-1-documentation">
<h1>verstack 2.0.1 Documentation<a class="headerlink" href="#verstack-2-0-1-documentation" title="Permalink to this headline">¶</a></h1>
<p>Machine learning tools to make a Data Scientist’s work efficient</p>
<p>veratack package contains the following tools:</p>
<ul class="simple">
<li><p><strong>DateParser</strong> automated date columns finder and parser</p></li>
<li><p><strong>LGBMTuner</strong> automated lightgbm models tuner with optuna</p></li>
<li><p><strong>NaNImputer</strong> impute all missing values in a pandas dataframe using advanced machine learning with 1 line of code</p></li>
<li><p><strong>Multicore</strong> execute any function in concurrency using all the available cpu cores</p></li>
<li><p><strong>ThreshTuner</strong> tune threshold for binary classification predictions</p></li>
<li><p><strong>stratified_continuous_split</strong> create train/test splits stratified on the continuous variable</p></li>
<li><p><strong>categoric_encoders</strong> encode categoric variable by numeric labels</p></li>
</ul>
<blockquote>
<div><ul class="simple">
<li><p><strong>Factorizer</strong> encode categoric variable by numeric labels</p></li>
<li><p><strong>OneHotEncoder</strong> represent categoric variable as a set of binary variables</p></li>
<li><p><strong>FrequencyEncoder</strong> encode categoric variable by class frequencies</p></li>
<li><p><strong>MeanTargetEncoder</strong> encode categoric variable by mean of the target variable</p></li>
<li><p><strong>WeightOfEvidenceEncoder</strong> encode categoric variable as a weight of evidence of a binary target variable</p></li>
</ul>
</div></blockquote>
<ul class="simple">
<li><p><strong>timer</strong> convenient timer decorator to quickly measure and display time of any function execution</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Getting verstack</p>
<p>$ <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">verstack</span></code></p>
<p>$ <code class="docutils literal notranslate"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">--upgrade</span> <span class="pre">verstack</span></code></p>
</div>
<section id="dateparser">
<h2>DateParser<a class="headerlink" href="#dateparser" title="Permalink to this headline">¶</a></h2>
<p>Fully automated DateParser tool that takes as input a pandas.DataFrame and returns a pandas.DataFrame with parsed datetime features.
Holidays flags and names are created as features subject to user passing the country argument (E.g. country = ‘US’). Holiday features extraction are based on utilizing the <cite>holidays</cite> package.
Datetime columns will be found automatically, transformed to pd.Timestamp format, new columns with the follwing features (if applicable to the specific datetime format) will be created:</p>
<blockquote>
<div><ul class="simple">
<li><p>year</p></li>
<li><p>month</p></li>
<li><p>day (monthday)</p></li>
<li><p>quarter</p></li>
<li><p>week</p></li>
<li><p>weekday</p></li>
<li><p>dayofyear</p></li>
<li><p>hour</p></li>
<li><p>minute</p></li>
<li><p>second</p></li>
<li><p>part_of_day</p></li>
<li><p>timediff (if two datetime columns are present)</p></li>
<li><p>is_holiday (different in different countries, even different states inside countries)</p></li>
<li><p>holiday_name</p></li>
<li><p>is_payday</p></li>
<li><p>days_from_epoch (1970/01/01)</p></li>
</ul>
<p>… same set of features will be created (with column name prefix) for each of the datetime columns DateParser detects.</p>
</div></blockquote>
<p><strong>Supported datetime formats</strong></p>
<blockquote>
<div><ul class="simple">
<li><p>‘28-OCT-90’,</p></li>
<li><p>‘28-OCT-1990’,</p></li>
<li><p>‘10/28/90’,</p></li>
<li><p>‘10/28/1990’,</p></li>
<li><p>‘28.10.90’,</p></li>
<li><p>‘28.10.1990’,</p></li>
<li><p>‘90/10/28’,</p></li>
<li><p>‘1990/10/28’,</p></li>
<li><p>‘4 Q 90’,</p></li>
<li><p>‘4 Q 1990’,</p></li>
<li><p>‘OCT 90’,</p></li>
<li><p>‘OCT 1990’,</p></li>
<li><p>‘43 WK 90’,</p></li>
<li><p>‘43 WK 1990’,</p></li>
<li><p>‘01:02’,</p></li>
<li><p>‘02:34’,</p></li>
<li><p>‘02:34.75’,</p></li>
<li><p>‘20-JUN-1990 08:03’,</p></li>
<li><p>‘20-JUN-1990 08:03:00’,</p></li>
<li><p>‘1990-06-20 08:03’,</p></li>
<li><p>‘1990-06-20 08:03:00.0’</p></li>
</ul>
</div></blockquote>
<p><strong>Initialize DateParser</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">DateParser</span>

<span class="c1"># initialize with default parameters</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">DateParser</span><span class="p">()</span>

<span class="c1"># initialize with selected parameters</span>
<span class="n">parser</span> <span class="o">=</span> <span class="n">DateParser</span><span class="p">(</span><span class="n">country</span> <span class="o">=</span> <span class="s1">&#39;US&#39;</span><span class="p">,</span>
                  <span class="n">state</span> <span class="o">=</span> <span class="s1">&#39;CA&#39;</span><span class="p">,</span>
                  <span class="n">payday</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
</pre></div>
</div>
<section id="parameters">
<h3>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">country</span></code> [default=None]</p>
<p>Country name or abreviation. For a full list of supported countries call parser.list_supported_countries()</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">state</span></code> [default=None]</p>
<p>State abreviation. Correct state abreviations are available at <a class="reference external" href="https://pypi.org/project/holidays/">https://pypi.org/project/holidays/</a></p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">prov</span></code> [default=None]</p>
<p>Province abreviation. Correct province abreviations are available at <a class="reference external" href="https://pypi.org/project/holidays/">https://pypi.org/project/holidays/</a></p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">payday</span></code> [default=None]</p>
<p>List of paydays applicable in a specific country. E.g. [1, 15]</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code> [default=True]</p>
<p>Enable or desable console prints</p>
</li>
</ul>
</section>
<section id="methods">
<h3>Methods<a class="headerlink" href="#methods" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(df)</span></code></p>
<p>Fully automatic search of datetime columns and features extraction.
Apart from all the conventional datetime features will automatically parse holidays / paydays if specified and init.
Saves the found datetime columns names and feature extraction pipelines for the transform() method.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> [pd.DataFrame]</p>
<p>Data with raw features</p>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>returns</dt><dd><p>pd.DataFrame with new features</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(df)</span></code></p>
<p>Parse identical set of features from a new dataset. Usually applied to test set transformation.
E.g. if test set datetime columns include a short timeframe so that quarter feature is constant and thus should not be created, the dataset will still be populated by this feature in order to preserve the identical columns names and order between train/test sets. Think machine learning.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> [pd.DataFrame]</p>
<p>Data with raw features (test/valid set)</p>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>returns</dt><dd><p>pd.DataFrame with new features</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">parse_holidays(datetime_col_series,</span> <span class="pre">country,</span> <span class="pre">state,</span> <span class="pre">province,</span> <span class="pre">holiday_names)</span></code></p>
<p>Create series with holidays names or flags for a defined country based on series of datetime-like strings.</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">datetime_col_series</span></code> [pd.Series]</p>
<p>Series of datetime-like strings in line with supported_formats</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">country</span></code> [str]</p>
<p>Country name or abreviation. For a full list of supported countries call parser.list_supported_countries()</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">state</span></code> [str, default = None]</p>
<p>State abreviation. Correct state abreviations are available at <a class="reference external" href="https://pypi.org/project/holidays/">https://pypi.org/project/holidays/</a></p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">prov</span></code> [str, default = None]</p>
<p>Province abreviation. Correct province abreviations are available at <a class="reference external" href="https://pypi.org/project/holidays/">https://pypi.org/project/holidays/</a></p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">holiday_names</span></code> [bool, default = False]</p>
<p>Flag to return holidays as a binary feature or string holidays names</p>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>returns</dt><dd><p>pd.Series with holidays binary flags or holidays string names</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_holidays_calendar(country,</span> <span class="pre">years,</span> <span class="pre">state</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">prov</span> <span class="pre">=</span> <span class="pre">None)</span></code></p>
<p>Get data on the holidays in a given country (optinally in a certain state/province) for a given year(s).</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">country</span></code> [str]</p>
<p>Country name or abreviation. For a full list of supported countries call parser.list_supported_countries()</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">state</span></code> [str, default = None]</p>
<p>State abreviation. Correct state abreviations are available at <a class="reference external" href="https://pypi.org/project/holidays/">https://pypi.org/project/holidays/</a></p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">prov</span></code> [str, default = None]</p>
<p>Province abreviation. Correct province abreviations are available at <a class="reference external" href="https://pypi.org/project/holidays/">https://pypi.org/project/holidays/</a></p>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>returns</dt><dd><p>dictionary with holidays dates and names</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">list_supported_countries()</span></code></p>
<p>Print a list of supported countries and abreviations.</p>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">datetime_cols</span></code></p>
<p>List of found datetime columns names. Available after fit_transform()</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">created_datetime_cols</span></code></p>
<p>List of created datetime features. Available after fit_transform()</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">supported</span> <span class="pre">formats</span></code></p>
<p>List of supported datetime formats</p>
</li>
</ul>
</section>
<section id="examples">
<h3>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h3>
<p>Using LGBMTuner with all default parameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parser</span> <span class="o">=</span> <span class="n">DateParser</span><span class="p">()</span>
<span class="n">train_with_parsed_dt_feats</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">test_with_parsed_dt_feats</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
<p>DateParser with holidays/paydays</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">parser</span> <span class="o">=</span> <span class="n">DateParser</span><span class="p">(</span><span class="n">country</span> <span class="o">=</span> <span class="s1">&#39;US&#39;</span><span class="p">,</span> <span class="n">payday</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">15</span><span class="p">])</span>
<span class="n">train_with_parsed_dt_feats</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
<span class="n">test_with_parsed_dt_feats</span> <span class="o">=</span> <span class="n">parser</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="lgbmtuner">
<h2>LGBMTuner<a class="headerlink" href="#lgbmtuner" title="Permalink to this headline">¶</a></h2>
<p>Fully automated lightgbm model hyperparameter tuning class with optuna under the hood.
LGBMTuner selects optimal hyperparameters based on executed trials (configurable), optimizes n_estimators and fits the final model to the whole train set.
Feature importances are available in numeric format, as a static plot, and as an interactive plot (html).
Optimization history and parameters importance in static and interactive formats are alse accesable by built in methods.</p>
<section id="logic">
<h3>Logic<a class="headerlink" href="#logic" title="Permalink to this headline">¶</a></h3>
<p>The only required user inputs are the X (features), y (labels) and evaluation metric name, LGBMTuner will handle the rest</p>
<blockquote>
<div><ul class="simple">
<li><p>lgbm model type (regression/classification) is inferred from the labels and evaluation metric (passed by user)</p></li>
<li><p>optimization metric may be different from the evaluation metric (passed by user). LGBMTuner at hyperparameters search stage imploys the error reduction strategy, thus:
- most regression task type metrics are supported for optimization, if not, MSE is selected for optimization
- for classification task types hyperparameters are tuned by optimizing log_loss, n_estimators are tuned with evaluation_metric</p></li>
<li><p>early stopping is engaged at each stage of LGBMTuner optimizations</p></li>
<li><p>for every trial (iteration) a random train_test_split is performed (stratified for classification)</p></li>
<li><p>lgbm model initial parameters!=defaults and are inferred from the data stats and built in logic</p></li>
<li><p>optimization parameters and their search space are inferred from the data stats and built in logic</p></li>
<li><p>LGBMTuner class instance (after optimization) can be used for making predictions with conventional syntaxis (predict/predict_proba)</p></li>
<li><p>verbosity is controlled and by default outputs only the necessary optimization process/results information</p></li>
</ul>
</div></blockquote>
<p><strong>Initialize LGBMTuner</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">LGBMTuner</span>

<span class="c1"># initialize with default parameters</span>
<span class="n">tuner</span> <span class="o">=</span> <span class="n">LGBMTuner</span><span class="p">(</span><span class="s1">&#39;rmse&#39;</span><span class="p">)</span>

<span class="c1"># initialize with selected parameters</span>
<span class="n">tuner</span> <span class="o">=</span> <span class="n">LGBMTuner</span><span class="p">(</span><span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;rmse&#39;</span><span class="p">,</span>
                  <span class="n">trials</span> <span class="o">=</span> <span class="mi">200</span><span class="p">,</span>
                  <span class="n">refit</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                  <span class="n">verbosity</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                  <span class="n">visualization</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                  <span class="n">seed</span> <span class="o">=</span> <span class="mi">999</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id1">
<h3>Parameters<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">metric</span></code> [default=None]</p>
<dl class="simple">
<dt>Evaluation metric for hyperparameters optimization. LGBMTuner supports the following metrics (note the syntax)</dt><dd><p>[‘mae’, ‘mse’, ‘rmse’, ‘rmsle’, ‘mape’, ‘smape’, ‘rmspe’, ‘r2’, ‘auc’, ‘gini’, ‘log_loss’, ‘accuracy’, ‘balanced_accuracy’, ‘precision’, ‘precision_weighted’, ‘precision_macro’, ‘recall’, ‘recall_weighted’, ‘recall_macro’, ‘f1’, ‘f1_weighted’, ‘f1_macro’, ‘lift’]</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">trials</span></code> [default=100]</p>
<p>Number of trials to run</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">refit</span></code> [default=True]</p>
<p>Fit the model with optimized hyperparameters on the whole train set (required for feature_importances, plot_importances() and prediction methods)</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbosity</span></code> [default=1]</p>
<p>Console verbosity level: 0 - no output except for optuna CRITICAL errors and builtin exceptions;
(1-5) based on optuna.logging options. The default is 1</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">visualization</span></code> [default=True]</p>
<p>Automatically output feature_importance &amp; optimization plots into the console after tuning. Plots are also available on demand by corresponding methods</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">seed</span></code> [default=42]</p>
<p>Random state parameter</p>
</li>
</ul>
</section>
<section id="id2">
<h3>Methods<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit(X,</span> <span class="pre">y)</span></code></p>
<p>Execute LGBM model hyperparameters tuning</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code> [pd.DataFrame]</p>
<p>Train features</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code> [pd.Series]</p>
<p>Train labels</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimize_n_estimators(X,</span> <span class="pre">y,</span> <span class="pre">params,</span> <span class="pre">verbose_eval</span> <span class="pre">=</span> <span class="pre">100)</span></code></p>
<p>Optimize n_estimators for lgb model.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code> [np.array]</p>
<p>Train features</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code> [np.array]</p>
<p>Train labels</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code> [dict]</p>
<p>parameters to use for training the model with early stopping</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose_eval</span></code> [int]</p>
<p>evaluation output at each <code class="docutils literal notranslate"><span class="pre">verbose_eval</span></code> iteratio n</p>
</li>
</ul>
<dl class="simple">
<dt>returns</dt><dd><p>(best_iteration, best_score)</p>
</dd>
</dl>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_optimized(X,</span> <span class="pre">y)</span></code></p>
<p>Train model with tuned params on whole train data</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">X</span></code> [np.array]</p>
<p>Train features</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">y</span></code> [np.array]</p></li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict(test,</span> <span class="pre">threshold</span> <span class="pre">=</span> <span class="pre">0.5)</span></code></p>
<p>Predict by optimized model on new data</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">test</span></code> [pd.DataFrame]</p>
<p>Test features</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">threshold</span></code> [default=0.5]</p>
<p>Classification threshold (applicable for binary classification)</p>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>returns</dt><dd><p>array of int</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">predict_proba(test)</span></code></p>
<p>Predict probabilities by optimized model on new data</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">test</span></code> [pd.DataFrame]</p>
<p>Test features</p>
</li>
</ul>
</div></blockquote>
<dl class="simple">
<dt>returns</dt><dd><p>array of float</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">plot_importances(n_features</span> <span class="pre">=</span> <span class="pre">15,</span> <span class="pre">figsize</span> <span class="pre">=</span> <span class="pre">(10,6),</span> <span class="pre">interactive</span> <span class="pre">=</span> <span class="pre">False)</span></code></p>
<p>Plot feature importance</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">n_features</span></code> [default=15]</p>
<p>Number of important features to plot</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">figsize</span></code> [default=(10,6)]</p>
<p>plot size</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">interactive</span></code> [default=False]</p>
<p>Create &amp; display with the default browser the interactive html plot or (if browser disply is unavailable) save to current wd.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">plot_optimization_history(interactive</span> <span class="pre">=</span> <span class="pre">False)</span></code></p>
<p>Plot optimization function improvement history</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">interactive</span></code> [default=False]</p>
<p>Create &amp; display with the default browser the interactive html plot or (if browser disply is unavailable) save to current wd.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">plot_param_importances(interactive</span> <span class="pre">=</span> <span class="pre">False)</span></code></p>
<p>Plot params importance plot</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">interactive</span></code> [default=False]</p>
<p>Create &amp; display with the default browser the interactive html plot or (if browser disply is unavailable) save to current wd.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">plot_intermediate_values(interactive</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">legend</span> <span class="pre">=</span> <span class="pre">False)</span></code></p>
<p>Plot optimization trials history. Shows successful and terminated trials. If trials &gt; 50 it is better to study the interactive version</p>
<blockquote>
<div><ul>
<li><p><code class="docutils literal notranslate"><span class="pre">interactive</span></code> [default=False]</p>
<p>Create &amp; display with the default browser the interactive html plot or (if browser disply is unavailable) save to current wd.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">legend</span></code> [default=False]</p>
<p>Plot legen on a static plot</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">metric</span></code></p>
<p>Evaluation metric defined by user at LGBMTuner init</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">refit</span></code></p>
<p>Setting for refitting the optimized model on whole train dataset</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbosity</span></code></p>
<p>Verbosity level settings</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">visualization</span></code></p>
<p>Automatic plots output after optimization setting</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">seed</span></code></p>
<p>Random state value</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">fitted_model</span></code></p>
<p>Trained LGBM booster model with optimized parameters</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">feature_importances</span></code></p>
<p>Feature importance values</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">study</span></code></p>
<p>optuna.study.study.Study object after hyperparameters tuning</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">init_params</span></code></p>
<p>initial LGBM model parameters</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">best_params</span></code></p>
<p>learned optimized parameters</p>
</li>
</ul>
</section>
<section id="id3">
<h3>Examples<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p>Using LGBMTuner with all default parameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">LGBMTuner</span><span class="p">(</span><span class="s1">&#39;auc&#39;</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">feature_importances</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">plot_importances</span><span class="p">()</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">plot_intermediate_values</span><span class="p">()</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">plot_optimization_history</span><span class="p">()</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">plot_param_importances</span><span class="p">()</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">best_params</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
<p>LGBMTuner with custom settings</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">LGBMTuner</span><span class="p">(</span><span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;auc&#39;</span><span class="p">,</span> <span class="n">trials</span> <span class="o">=</span> <span class="mi">300</span><span class="p">,</span> <span class="n">verbosity</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">visualization</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">plot_importances</span><span class="p">(</span><span class="n">legend</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">plot_intermediate_values</span><span class="p">(</span><span class="n">interactive</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">,</span> <span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="nanimputer">
<h2>NaNImputer<a class="headerlink" href="#nanimputer" title="Permalink to this headline">¶</a></h2>
<p>Impute all missing values in a pandas dataframe by xgboost models in multiprocessing mode using a single line of code.</p>
<section id="id4">
<h3>Logic<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>With NaNImputer you can fill missing values in numeric, binary and categoric columns in your pandas dataframe using advanced XGBRegressor/XGBClassifier models with just 1 line of code. Regardless of the data types in your dataframe (string/bool/numeric):</p>
<blockquote>
<div><ul class="simple">
<li><p>all of the columns will be checked for missing values</p></li>
<li><p>transformed into numeric formats</p></li>
<li><p>split into subsets with and without missing values</p></li>
<li><p>applicalbe models will be selected and configured for each of the columns with NaNs</p></li>
<li><p>models will be trained in multiprocessing mode utilizing all the available cores and threads of your cpu (this saves a lot of time)</p></li>
<li><p>NaNs will be predicted and placed into corresponding indixes</p></li>
<li><p>columns with all NaNs will be droped</p></li>
<li><p>columns containing NaNs and known values as a single constant</p></li>
<li><p>data will be reverse-transformed into original format</p></li>
</ul>
</div></blockquote>
<p>The module is highly configurable with default argumets set for the highest performance and verbosity</p>
<p>The only limitation is:</p>
<ul class="simple">
<li><p>NaNs in pure text columns are not imputed. By default they are filled with ‘Missing_data’ value. Configurable. If disabled - will return these columns with missing values untouched</p></li>
</ul>
<p><strong>Initialize NaNImputer</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">NaNImputer</span>

<span class="c1"># initialize with default parameters</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">NaNImputer</span><span class="p">()</span>

<span class="c1"># initialize with selected parameters</span>
<span class="n">imputer</span> <span class="o">=</span> <span class="n">NaNImputer</span><span class="p">(</span><span class="n">conservative</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                     <span class="n">n_feats</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                     <span class="n">nan_cols</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                     <span class="n">fix_string_nans</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">multiprocessing_load</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
                     <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">fill_nans_in_pure_text</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">drop_empty_cols</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="n">drop_nan_cols_with_constant</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id5">
<h3>Parameters<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">conservative</span></code> [default=False]</p>
<p>Model complexity level used to impute missing values. If <code class="docutils literal notranslate"><span class="pre">True</span></code>: model will be set to less complex and much faster.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_feats</span></code> [default=10]</p>
<p>Number of corellated independent features to be used forcorresponding column (with NaN) model training and imputation.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">nan_cols</span></code> [default=None]</p>
<p>List of columns to impute missing values in. If None: all the columns with missing values will be used.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">fix_string_nans</span></code> [default=True]</p>
<p>Find possible missing values in numeric columns that had been (mistakenly) encoded as strings, E.g. ‘Missing’/’NaN’/’No data’ and replace them with np.nan for further imputation.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">multiprocessing_load</span></code> [default=3]</p>
<ul class="simple">
<li><p>Levels of parallel multiprocessing compute
- 1 = single core
- 2 = half of all available cores
- 3 = all available cores</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code> [default=True]</p>
<p>Print the imputation progress.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">fill_nans_in_pure_text</span></code> [default=True]</p>
<p>Fill the missing values in text fields by string ‘Missing_data’.Applicable for text fields (not categoric).</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_empty_cols</span></code> [default=True]</p>
<p>Drop columns with all NaNs.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">drop_nan_cols_with_constant</span></code> [default=True]</p>
<p>Drop columns containing NaNs and known values as a single constant.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">feature_selection</span></code> [default=”correlation”]
- Define algorithm to select most important feats for each column imputation. Quick option: “correlation” is based on selecting n_feats with the highest binary correlation with each column for NaNs imputation. Less quick but more precise: “feature_importance” is based on extracting feature_importances from an xgboost model.</p></li>
</ul>
</section>
<section id="id6">
<h3>Methods<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">impute(data)</span></code></p>
<p>Execute NaNs imputation columnwise in a pd.DataFrame</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">data</span></code> pd.DataFrame</p>
<p>dataframe with missing values in a single/multiple columns</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id7">
<h3>Examples<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h3>
<p>Using NaNImputer with all default parameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">NaNImputer</span><span class="p">()</span>
<span class="n">df_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">impute</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<p>Say you would like to impute missing values in a list of specific columns, use 20 most important features for each of these columns imputation and deploy a half of the available cpu cores</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">imputer</span> <span class="o">=</span> <span class="n">NaNImputer</span><span class="p">(</span><span class="n">nan_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">,</span> <span class="s1">&#39;col2&#39;</span><span class="p">],</span> <span class="n">n_feats</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">multiprocessing_load</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">df_imputed</span> <span class="o">=</span> <span class="n">imputer</span><span class="o">.</span><span class="n">impute</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="multicore">
<h2>Multicore<a class="headerlink" href="#multicore" title="Permalink to this headline">¶</a></h2>
<p>Execute any function in concurrency using all the available cpu cores.</p>
<section id="id8">
<h3>Logic<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><p>Multicore module is built on top of concurrent.futures package. Passed iterables are divided into chunks according to the number of workers and passed into separate processes.</p>
<p>Results are extracted from finished processes and combined into a single/multiple output as per the defined function output requirements.</p>
<p>Multiple outputs are returned as a nested list.</p>
</div></blockquote>
<p><strong>Initialize Multicore</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">Multicore</span>

<span class="c1"># initialize with default parameters</span>
<span class="n">multicore</span> <span class="o">=</span> <span class="n">Multicore</span><span class="p">()</span>

<span class="c1"># initialize with selected parameters</span>
<span class="n">multicore</span> <span class="o">=</span> <span class="n">Multicore</span><span class="p">(</span><span class="n">workers</span> <span class="o">=</span> <span class="mi">6</span><span class="p">,</span>
                      <span class="n">multiple_iterables</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id9">
<h3>Parameters<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">workers</span></code> int or bool [default=False]</p>
<p>Number of workers if passed by user. If <code class="docutils literal notranslate"><span class="pre">False</span></code>: all available cpu cores will be used.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">multiple_iterables</span></code> bool [default=False]</p>
<p>If function needs to iterate over multiple iterables, set to <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>Multiple iterables must be passed as a list (see examples below).</p>
</li>
</ul>
</section>
<section id="id10">
<h3>Methods<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">execute(func,</span> <span class="pre">iterable)</span></code></p>
<p>Execute passed function and iterable(s) in concurrency.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">func</span></code> function</p>
<p>function to execute in parallel</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">iterable</span></code> list/pd.Series/pd.DataFrame/dictionary</p>
<p>data to iterate over</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id11">
<h3>Examples<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p>Use Multicore with all default parameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">multicore</span> <span class="o">=</span> <span class="n">Multicore</span><span class="p">()</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">multicore</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">iterable_list</span><span class="p">)</span>
</pre></div>
</div>
<p>If you want to use a limited number of cpu cores and need to iterate over two objects:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">multicore</span> <span class="o">=</span> <span class="n">Multicore</span><span class="p">(</span><span class="n">workers</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">multiple_iterables</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">multicore</span><span class="o">.</span><span class="n">execute</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="p">[</span><span class="n">iterable_dataframe</span><span class="p">,</span> <span class="n">iterable_list</span><span class="p">])</span>
</pre></div>
</div>
</section>
</section>
<section id="threshtuner">
<h2>ThreshTuner<a class="headerlink" href="#threshtuner" title="Permalink to this headline">¶</a></h2>
<p>Find the best threshold to split your predictions in a binary classification task. Most applicable for imbalance target cases.
In addition to thresholds &amp; loss_func scores, the predicted_ratio (predicted fraction of 1) will be calculated and saved for every threshold. This will help the identify the appropriate threshold not only based on the score, but also based on the resulting distribution of 0 and 1 in the predictions.</p>
<section id="id12">
<h3>Logic<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<blockquote>
<div><dl class="simple">
<dt>Default behavior (only pass the labels and predictions):</dt><dd><ul class="simple">
<li><p>Calculate the labels balance (fraction_of_1 in labels)</p></li>
<li><p>Define the min_threshold as fraction_of_1 * 0.8</p></li>
<li><p>Define the max_threshold as fraction_of_1 * 1.2 but not greater than 1</p></li>
<li><p>Define the n_thresholds = 200</p></li>
<li><p>Create 200 threshold options uniformly distributed between min_threshold &amp; max_threshold</p></li>
<li><p>Deploy the balanced_accuracy_score as loss_func</p></li>
<li><p>Peform loss function calculation and save results in class instance placeholders</p></li>
</ul>
</dd>
<dt>Customization options</dt><dd><ul class="simple">
<li><p>Change the n_thresholds to the desired value</p></li>
<li><p>Change the min_threshold &amp; max_threshold to the desired values</p></li>
<li><p>Pass the loss_func of choice, e.g. sklearn.metrics.f1_score</p></li>
</ul>
</dd>
</dl>
<p>This will result in user defined granulation of thresholds to test</p>
</div></blockquote>
<p><strong>Initialize ThreshTuner</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">ThreshTuner</span>

<span class="c1"># initialize with default parameters</span>
<span class="n">thresh</span> <span class="o">=</span> <span class="n">ThreshTuner</span><span class="p">()</span>

<span class="c1"># initialize with selected parameters</span>
<span class="n">thresh</span> <span class="o">=</span> <span class="n">ThreshTuner</span><span class="p">(</span><span class="n">n_thresholds</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span>
                     <span class="n">min_threshold</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                     <span class="n">max_threshold</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="id13">
<h3>Parameters<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">n_thresholds</span></code> int [default=200]</p>
<p>Number of thresholds to test. If not set by user: 200 thresholds will be tested.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">min_threshold</span></code> float or int [default=None]</p>
<p>Minimum threshold value. If not set by user: will be inferred from labels balance based on fraction_of_1</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_threshold</span></code> float or int [default=None]</p>
<p>Maximum threshold value. If not set by user: will be inferred from labels balance based on fraction_of_1</p>
</li>
</ul>
</section>
<section id="id14">
<h3>Methods<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit(labels,</span> <span class="pre">pred,</span> <span class="pre">loss_func)</span></code></p>
<p>Calculate loss_func results for labels &amp; preds for the defined/default thresholds. Print the threshold(s) with the best loss_func scores</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">labels</span></code> array/list/series [default=balanced_accuracy_score]</p>
<p>y_true labels represented as 0 or 1</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">pred</span></code> array/list/series</p>
<p>predicted probabilities of 1</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">loss_func</span></code> function</p>
<p>loss function for scoring the predictions, e.g. sklearn.metrics.f1_score</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">result()</span></code></p>
<p>Display a dataframe with thresholds/loss_func_scores/fraction_of_1 for for all the the defined/default thresholds</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">best_score()</span></code></p>
<p>Display a dataframe with thresholds/loss_func_scores/fraction_of_1 for the best loss_func_score</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">best_predict_ratio()</span></code></p>
<p>Display a dataframe with thresholds/loss_func_scores/fraction_of_1 for the (predicted) fraction_of_1 which is closest to the (actual) labels_fraction_of_1</p>
</li>
</ul>
</section>
<section id="id15">
<h3>Examples<a class="headerlink" href="#id15" title="Permalink to this headline">¶</a></h3>
<p>Use ThreshTuner with all default parameters</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">thresh</span> <span class="o">=</span> <span class="n">ThreshTuner</span><span class="p">()</span>
<span class="n">thres</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
<p>Customized ThreshTuner application</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">f1_score</span>

<span class="n">thresh</span> <span class="o">=</span> <span class="n">ThreshTuner</span><span class="p">(</span><span class="n">n_thresholds</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="n">min_threshold</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">max_threshold</span> <span class="o">=</span> <span class="mf">0.6</span><span class="p">)</span>
<span class="n">thresh</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">)</span>
</pre></div>
</div>
<p>Access the results after .fit()</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">thresh</span> <span class="o">=</span> <span class="n">ThreshTuner</span><span class="p">()</span>
<span class="n">thres</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

<span class="c1"># return pd.DataFrame with all the results</span>
<span class="n">thresh</span><span class="o">.</span><span class="n">result</span>
<span class="c1"># return pd.DataFrame with the best loss_func score</span>
<span class="n">thresh</span><span class="o">.</span><span class="n">best_score</span><span class="p">()</span>
<span class="n">thresh</span><span class="o">.</span><span class="n">best_score</span><span class="p">()[</span><span class="s1">&#39;threshold&#39;</span><span class="p">]</span>
<span class="c1"># return pd.DataFrame with the best predicted fraction_of_1</span>
<span class="n">thresh</span><span class="o">.</span><span class="n">best_predict_ratio</span><span class="p">()</span>
<span class="c1"># return the actual labels fraction_of_1</span>
<span class="n">thresh</span><span class="o">.</span><span class="n">labels_fractio_of_1</span>
</pre></div>
</div>
</section>
</section>
<section id="stratified-continuous-split">
<h2>stratified_continuous_split<a class="headerlink" href="#stratified-continuous-split" title="Permalink to this headline">¶</a></h2>
<dl class="simple">
<dt>Create stratified splits based on either continuous or categoric target variable.</dt><dd><ul class="simple">
<li><p>For continuous target variable verstack uses binning and categoric split based on bins</p></li>
<li><p>For categoric target enhanced sklearn.model_selection.train_test_split is used: in case there are not enough categories for the split, the minority classes will be combined with nearest neighbors.</p></li>
</ul>
</dd>
</dl>
<p>Can accept only pandas.DataFrame/pandas.Series as data input.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">verstack</span><span class="o">.</span><span class="n">stratified_continuous_split</span><span class="o">.</span><span class="n">scsplit</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span>
                                             <span class="n">stratify</span><span class="p">,</span>
                                             <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span>
                                             <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">,</span>
                                             <span class="n">continuous</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                                             <span class="n">random_state</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>
</div>
<section id="id16">
<h3>Parameters<a class="headerlink" href="#id16" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">X,y,data</span></code></p>
<p>data input for the split in pandas.DataFrame/pandas.Series format.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">stratify</span></code></p>
<p>target variable for the split in pandas/eries format.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">test_size</span></code> [default=0.3]</p>
<p>test split ratio.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">train_size</span></code> [default=0.7]</p>
<p>train split ratio.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">continuous</span></code> [default=True]</p>
<p>stratification target definition. If True, verstack will perform the stratification on the continuous target variable, if False, sklearn.model_selection.train_test_split will be performed with verstack enhancements.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">random_state</span></code> [default=5]</p>
<p>random state value.</p>
</li>
</ul>
</section>
<section id="id17">
<h3>Examples<a class="headerlink" href="#id17" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack.stratified_continuous_split</span> <span class="kn">import</span> <span class="n">scsplit</span>

<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">scsplit</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;continuous_column_name&#39;</span><span class="p">])</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">scsplit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span>
                                         <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="categoric-encoders">
<h2>categoric_encoders<a class="headerlink" href="#categoric-encoders" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the categoric encoders are conveniently integrated to work with pandas.DataFrame. Modules receive pd.DataFrame and kwargs as inputs and return pd.DataFrame with encoded column. All the necessary attributes for further transform/inverse_transform are saved in instance objects and can be seralized (e.g. pickle) for latter application.</p>
</div>
<section id="factorizer">
<h3>Factorizer<a class="headerlink" href="#factorizer" title="Permalink to this headline">¶</a></h3>
<p>Encode categoric column by numeric labels.</p>
<section id="id18">
<h4>Logic<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h4>
<p>Assign numeric labels starting with 0 to all unique variable’s categories.</p>
<p>Missing values can be encoded by an integer value (defaults to -1) / float / string or can be left untransformed.</p>
<p>When transform () - unseen categories will be be represented as NaN.</p>
<p><strong>Initialize Factorizer</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">Factorizer</span>

<span class="c1"># initialize with default parameters</span>
<span class="n">factorizer</span> <span class="o">=</span> <span class="n">Factorizer</span><span class="p">()</span>

<span class="c1"># initialize with changing the NaN encoding value</span>
<span class="n">factorizer</span> <span class="o">=</span> <span class="n">Factorizer</span><span class="p">(</span><span class="n">na_sentinel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span> <span class="c1">#-999/0.33333/&#39;No data&#39;)</span>
</pre></div>
</div>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code></p>
<p>Defined (at init) missing values encoding value.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code></p>
<p>Defined (at fit_transform()) column that had been transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">pattern</span></code></p>
<p>Defined (at fit_transform()) encoding map.</p>
</li>
</ul>
</section>
<section id="id19">
<h4>Parameters<a class="headerlink" href="#id19" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code> [default=-1]</p>
<p>Missing values encoding value. Can take int/float/str/np.nan values.</p>
</li>
</ul>
</section>
<section id="id20">
<h4>Methods<a class="headerlink" href="#id20" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(df,</span> <span class="pre">colname)</span></code></p>
<p>Fit Factorizer to data and return transformed data.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>df containing the colname to transform.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code> str</p>
<p>Column name in df to be transformed.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(df)</span></code></p>
<p>Apply the fitted Factorizer to new data and return transformed data. Unseen categories will be represented by NaN.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_transform(df)</span></code></p>
<p>Inverse transform data that had been encoded by Factorizer. Data must contain colname that was passed at fit_transform().</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id21">
<h4>Examples<a class="headerlink" href="#id21" title="Permalink to this headline">¶</a></h4>
<p>Use with default na_sentinel:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">factorizer</span> <span class="o">=</span> <span class="n">Factorizer</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">factorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">)</span> <span class="c1"># will encode NaN values by -1</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">factorizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">factorizer</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">factorizer</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
<p>Keep missing values untransformed:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">factorizer</span> <span class="o">=</span> <span class="n">Factorizer</span><span class="p">(</span><span class="n">na_sentinel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">)</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">factorizer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="onehotencoder">
<h3>OneHotEncoder<a class="headerlink" href="#onehotencoder" title="Permalink to this headline">¶</a></h3>
<p>Encode categoric column by a set of binary columns.</p>
<section id="id22">
<h4>Logic<a class="headerlink" href="#id22" title="Permalink to this headline">¶</a></h4>
<p>Categoric ‘column’:[‘a’,’b’,’c’] will be represented by three binary columns ‘a’, ‘b’, ‘c’. Original categoric ‘column’ is droped.</p>
<p>Missing values can be represented by a separate column or omited.</p>
<p>When transform() - unseen categories will not be represented by new columns, missing categories will be represented by empty (all zeros) columns.</p>
<p><strong>Initialize OneHotEncoder</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">)</span> <span class="c1"># will create a separate column for NaN values (if any)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code></p>
<p>Defined (at init) missing values encoding value.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code></p>
<p>Defined (at fit_transform()) column that had been transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">categories</span></code></p>
<p>Defined (at fit_transform()) unique class categories which will be represented by binary columns.</p>
</li>
</ul>
</section>
<section id="id23">
<h4>Parameters<a class="headerlink" href="#id23" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code> [default=True]</p>
<p>If True: create separate class column for NaN values.</p>
</li>
</ul>
</section>
<section id="id24">
<h4>Methods<a class="headerlink" href="#id24" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(df,</span> <span class="pre">colname,</span> <span class="pre">prefix)</span></code></p>
<p>Fit OneHotEncoder to data and return transformed data.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>df containing the colname to transform.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code> str</p>
<p>Column name in df to be transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">prefix</span></code> str/int/float/bool/None, optional</p>
<p>String to append DataFrame column names. The default is None.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(df)</span></code></p>
<p>Apply the fitted OneHotEncoder to new data and return transformed data. Unseen categories will not be represented by new columns, missing categories will be represented by empty (all zeros) columns.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_transform(df)</span></code></p>
<p>Inverse transform data that had been encoded by OneHotEncoder. Data must contain one-hot-encoded columns that was created at fit_transform().</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id25">
<h4>Examples<a class="headerlink" href="#id25" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">,</span> <span class="n">prefix</span> <span class="o">=</span> <span class="s1">&#39;colname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="frequencyencoder">
<h3>FrequencyEncoder<a class="headerlink" href="#frequencyencoder" title="Permalink to this headline">¶</a></h3>
<p>Encoder to represent categoric variable classes’ frequency across the dataset.</p>
<section id="id26">
<h4>Logic<a class="headerlink" href="#id26" title="Permalink to this headline">¶</a></h4>
<blockquote>
<div><p>Original column [‘a’, ‘a’, ‘a’, ‘b’, ‘b’, ‘c’, ‘c’, ‘c’, ‘c’, np.nan]</p>
<p>Encoded column  [0.3, 0.3, 0.3, 0.2, 0.2, 0.4, 0.4, 0.4, 0.4, 0.1] # np.nan]</p>
</div></blockquote>
<p>When transform() - unseen categories will be represented by the most common (highest) frequency.</p>
<p>Can handle missing values - encode NaN by NaN frequency or leave NaN values untransformed.
Resulting frequencies are normalized as a percentage.</p>
<p><strong>Initialize FrequencyEncoder</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">FrequencyEncoder</span>
<span class="n">fe</span> <span class="o">=</span> <span class="n">FrequencyEncoder</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">fe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">fe</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">fe</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">fe</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code></p>
<p>Defined (at init) missing values encoding value.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code></p>
<p>Defined (at fit_transform()) column that had been transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">pattern</span></code></p>
<p>Defined (at fit_transform()) encoding map.</p>
</li>
</ul>
</section>
<section id="id27">
<h4>Parameters<a class="headerlink" href="#id27" title="Permalink to this headline">¶</a></h4>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code> [default=True]</p>
<ul>
<li><p>If True: Encode NaN values by their frequency. If False return np.nan in the encoded column.</p></li>
</ul>
</li>
</ul>
</section>
<section id="id28">
<h4>Methods<a class="headerlink" href="#id28" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(df,</span> <span class="pre">colname)</span></code></p>
<p>Fit FrequencyEncoder to data and return transformed data.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>df containing the colname to transform.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code> str</p>
<p>Column name in df to be transformed.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(df)</span></code></p>
<p>Apply the fitted FrequencyEncoder to new data and return transformed data. Unseen categories will be represented as NaN.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_transform(df)</span></code></p>
<p>Inverse transform data that had been encoded by FrequencyEncoder. Data must contain colname that was passed at fit_transform().</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id29">
<h4>Examples<a class="headerlink" href="#id29" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">frequency_encoder</span> <span class="o">=</span> <span class="n">FrequencyEncoder</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">frequency_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">frequency_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">frequency_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">frequency_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="meantargetencoder">
<h3>MeanTargetEncoder<a class="headerlink" href="#meantargetencoder" title="Permalink to this headline">¶</a></h3>
<p>Encode train cat cols by mean target value for category.</p>
<section id="id30">
<h4>Logic<a class="headerlink" href="#id30" title="Permalink to this headline">¶</a></h4>
<p>To avoid target leakage train set encoding is performed by breaking data into 5 folds &amp;
encoding categories of each fold with their respective target mean values calculated on the other 4 folds.
This will introduce minor noize to train data encoding (at fit_transform()) as a normalization technique.
Test set (transform()) is encoded without normalization.</p>
<p>When transform() - unseen categories will be represented by the global target mean.</p>
<p>Can handle missing values - encode NaN by global mean or leave NaN values untransformed.</p>
<p><strong>Initialize MeanTargetEncoder</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">MeanTargetEncoder</span>
<span class="n">mean_target_encoder</span> <span class="o">=</span> <span class="n">MeanTargetEncoder</span><span class="p">(</span><span class="n">save_inverse_transform</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">,</span> <span class="s1">&#39;targetname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code></p>
<p>Defined (at init) missing values encoding value.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code></p>
<p>Defined (at fit_transform()) column that had been transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">pattern</span></code></p>
<p>Defined (at fit_transform()) encoding map.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_inverse_transform</span></code></p>
<p>Defined (at init) flag for saving the pattern for inverse transform.</p>
</li>
</ul>
</section>
<section id="id31">
<h4>Parameters<a class="headerlink" href="#id31" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code> [default=True]</p>
<p>If True: Encode NaN values by target global mean. If False return np.nan in the encoded column.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">save_inverse_transform</span></code> [default=False]</p>
<p>If True: Saves mean target values for each category at each encoding fold. Enable if need to inverse_transform the encoded data. Defaults to False because for large datasets saved pattern can significantly increase instance object size.</p>
</li>
</ul>
</section>
<section id="id32">
<h4>Methods<a class="headerlink" href="#id32" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(df,</span> <span class="pre">colname,</span> <span class="pre">targetname)</span></code></p>
<p>Fit MeanTargetEncoder to data and return transformed data.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>df containing the colname to transform.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code> str</p>
<p>Column name in df to be transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">targetname</span></code> str</p>
<p>Target column name in df for extracting the mean values for each colname category.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(df)</span></code></p>
<p>Apply the fitted MeanTargetEncoder to new data and return transformed data. Unseen categories will be encoded by the global target mean.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_transform(df)</span></code></p>
<p>Inverse transform data that had been encoded by MeanTargetEncoder. Data must contain colname that was passed at fit_transform().</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id33">
<h4>Examples<a class="headerlink" href="#id33" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mean_target_encoder</span> <span class="o">=</span> <span class="n">MeanTargetEncoder</span><span class="p">(</span><span class="n">save_inverse_transform</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">,</span> <span class="s1">&#39;targetname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">mean_target_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="weightofevidenceencoder">
<h3>WeightOfEvidenceEncoder<a class="headerlink" href="#weightofevidenceencoder" title="Permalink to this headline">¶</a></h3>
<p>Encoder to represent categoric variables by Weight of Evidence in regards to the binary target variable.</p>
<section id="id34">
<h4>Logic<a class="headerlink" href="#id34" title="Permalink to this headline">¶</a></h4>
<p>Built on top of sclearn package <a class="reference external" href="https://contrib.scikit-learn.org/category_encoders/woe.html#">category_encoders.woe.WOEEncoder</a>.</p>
<p>If encoded value is negative - it represents a category that is more heavily enclided to the negative target class (0).
Positive encoding result represents inclination to the positive target class (1).</p>
<p>When fit_transform() is used on a train set, variable is encoded with adding minor noize to reduce the risk of overfitting.</p>
<p>Can handle missing values - encode NaN by zero WoE or leave NaN untransformed.</p>
<p><strong>Initialize WeightOfEvidenceEncoder</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack</span> <span class="kn">import</span> <span class="n">WeightOfEvidenceEncoder</span>
<span class="n">WOE</span> <span class="o">=</span> <span class="n">WeightOfEvidenceEncoder</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">,</span> <span class="s1">&#39;targetname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Attributes</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code></p>
<p>Defined (at init) missing values encoding value.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code></p>
<p>Defined (at fit_transform()) column that had been transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">params</span></code></p>
<p>Defined (at init) category_encoders.woe.WOEEncoder <a class="reference external" href="https://contrib.scikit-learn.org/category_encoders/woe.html#">parameters</a></p>
</li>
</ul>
</section>
<section id="id36">
<h4>Parameters<a class="headerlink" href="#id36" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">na_sentinel</span></code> [default=True]</p>
<p>If True: Encode NaN values by zero WoE. If False return np.nan in the encoded column.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">kwargs</span></code></p>
<p>category_encoders.woe.WOEEncoder <a class="reference external" href="https://contrib.scikit-learn.org/category_encoders/woe.html#">parameters</a>. Following parameters are set by default: <code class="docutils literal notranslate"><span class="pre">'randomized':True</span></code>, <code class="docutils literal notranslate"><span class="pre">'random_state':42</span></code>, <code class="docutils literal notranslate"><span class="pre">'handle_missing':'return_nan'</span></code> &lt;- inferred from na_sentinel setting.</p>
</li>
</ul>
</section>
<section id="id38">
<h4>Methods<a class="headerlink" href="#id38" title="Permalink to this headline">¶</a></h4>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">fit_transform(df,</span> <span class="pre">colname,</span> <span class="pre">targetname)</span></code></p>
<p>Fit WeightOfEvidenceEncoder to data and return transformed data.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>df containing the colname to transform.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">colname</span></code> str</p>
<p>Column name in df to be transformed.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">targetname</span></code> str</p>
<p>Target column name in df for calculating WoE for each colname category.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">transform(df)</span></code></p>
<p>Apply the fitted WeightOfEvidenceEncoder to new data and return transformed data. Unseen categories’ WoE is set to 0.</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inverse_transform(df)</span></code></p>
<p>Inverse transform data that had been encoded by WeightOfEvidenceEncoder. Data must contain colname that was passed at fit_transform().</p>
<blockquote>
<div><p>Parameters</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">df</span></code> pd.DataFrame</p>
<p>Data containing the colname to transform.</p>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</section>
<section id="id39">
<h4>Examples<a class="headerlink" href="#id39" title="Permalink to this headline">¶</a></h4>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">WOE</span> <span class="o">=</span> <span class="n">WeightOfEvidenceEncoder</span><span class="p">()</span>
<span class="n">train_encoded</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="s1">&#39;colname&#39;</span><span class="p">,</span> <span class="s1">&#39;targetname&#39;</span><span class="p">)</span>
<span class="n">test_encoded</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>

<span class="n">train_reversed_to_original</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">train_encoded</span><span class="p">)</span>
<span class="n">test_reversed_to_original</span> <span class="o">=</span> <span class="n">WOE</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">test_encoded</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="timer">
<h2>timer<a class="headerlink" href="#timer" title="Permalink to this headline">¶</a></h2>
<p>Timer decorator to measure any function execution time and create elapsed time output: hours/minues/seconds will be calculated and returned conveniently.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">verstack</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">timer</span>
</pre></div>
</div>
<section id="id40">
<h3>Examples<a class="headerlink" href="#id40" title="Permalink to this headline">¶</a></h3>
<p>timer is a decorator function: it must placed above the function (that needs to be timed) definition</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">verstack.tools</span> <span class="kn">import</span> <span class="n">timer</span>

<span class="nd">@timer</span>
<span class="k">def</span> <span class="nf">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Result is: </span><span class="si">{</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">func</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="o">&gt;&gt;&gt;</span><span class="n">Result</span> <span class="ow">is</span><span class="p">:</span> <span class="mi">5</span>
<span class="o">&gt;&gt;&gt;</span><span class="n">Time</span> <span class="n">elapsed</span> <span class="k">for</span> <span class="n">func</span> <span class="n">execution</span><span class="p">:</span> <span class="mf">0.0002</span> <span class="n">seconds</span>
</pre></div>
</div>
</section>
</section>
<section id="links">
<h2>Links<a class="headerlink" href="#links" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/DanilZherebtsov/verstack">Git</a></p>
<p><a class="reference external" href="https://pypi.org/project/verstack/">pypi</a></p>
<p><a class="reference external" href="https://www.linkedin.com/in/danil-zherebtsov/">author</a></p>
</section>
</section>


          </div>
            
        </div>
        <div class="clearfix"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="nav-item nav-item-0"><a href="#">verstack 0.1.1 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">verstack 2.0.1 Documentation</a></li> 
      </ul>
    </div>
<script type="text/javascript">
  $("#mobile-toggle a").click(function () {
    $("#left-column").toggle();
  });
</script>
<script type="text/javascript" src="_static/js/bootstrap.js"></script>
  <div class="footer">
    &copy; Copyright 2020, Danil Zherebtsov. Created using <a href="http://sphinx.pocoo.org/">Sphinx</a>.
  </div>
  </body>
</html>